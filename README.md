# Diverse-3D-Hand-Gesture-Prediction
[CVPR 2023] Dataset and Code Pytorch Implementation of [Diverse 3D Hand Gesture Prediction from Body Dynamics by Bilateral Hand Disentanglement](https://openaccess.thecvf.com/content/CVPR2023/html/Qi_Diverse_3D_Hand_Gesture_Prediction_From_Body_Dynamics_by_Bilateral_CVPR_2023_paper.html) 

[Xingqun Qi](https://scholar.google.com.hk/citations?hl=zh-CN&user=3tO41a8AAAAJ&view_op=list_works&sortby=pubdate), [Chen Liu](https://scholar.google.com/citations?hl=zh-CN&user=HmvE2WsAAAAJ&view_op=list_works&sortby=pubdate), [Muyi Sun](https://scholar.google.com/citations?user=Ti7NNqMAAAAJ&hl=en), [Lincheng Li](https://scholar.google.com/citations?user=NYLsVscAAAAJ&hl=en), Changjie Fan, [Xin Yu](https://scholar.google.com/citations?user=oxdtuSEAAAAJ&hl=en)
![image](https://github.com/XingqunQi-lab/Diverse-3D-Hand-Gesture-Prediction/blob/main/image/pipeline.PNG)
# Dataset
[Our newly collected TED Hands Dataset is avaiable now.](https://drive.google.com/drive/folders/1TVaK8rvkdd6D-N8JwfOzJLq4ZqAXcxWr?usp=sharing)
# Code
We are organizing our code and will release the code soon. Sorry for the delay.
# Demo Video
[Please watch it on YouTube](https://www.youtube.com/watch?v=i0pIlbdIh60).
# Acknowledgement
Thanks for the pioneering works [Body2hands](https://github.com/facebookresearch/body2hands) and [Frankmocap](https://github.com/facebookresearch/frankmocap).
