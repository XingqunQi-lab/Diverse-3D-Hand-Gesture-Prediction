# Diverse-3D-Hand-Gesture-Prediction
### [CVPR 2023] Dataset and Code Pytorch Implementation 

[Diverse 3D Hand Gesture Prediction from Body Dynamics by Bilateral Hand Disentanglement](https://openaccess.thecvf.com/content/CVPR2023/html/Qi_Diverse_3D_Hand_Gesture_Prediction_From_Body_Dynamics_by_Bilateral_CVPR_2023_paper.html) 

[Xingqun Qi](https://scholar.google.com.hk/citations?hl=zh-CN&user=3tO41a8AAAAJ&view_op=list_works&sortby=pubdate), [Chen Liu](https://scholar.google.com/citations?hl=zh-CN&user=HmvE2WsAAAAJ&view_op=list_works&sortby=pubdate), [Muyi Sun](https://scholar.google.com/citations?user=Ti7NNqMAAAAJ&hl=en), [Lincheng Li](https://scholar.google.com/citations?user=NYLsVscAAAAJ&hl=en), Changjie Fan, [Xin Yu](https://scholar.google.com/citations?user=oxdtuSEAAAAJ&hl=en)
![image](https://github.com/XingqunQi-lab/Diverse-3D-Hand-Gesture-Prediction/blob/main/image/pipeline.PNG)
# Dataset
[Our newly collected TED Hands Dataset is available now.](https://drive.google.com/drive/folders/1TVaK8rvkdd6D-N8JwfOzJLq4ZqAXcxWr?usp=sharing)
# Code
We are organizing our code and will release the code soon. Sorry for the delay.
# Demo Video
[Please watch it on YouTube](https://www.youtube.com/watch?v=i0pIlbdIh60).
# Acknowledgement
Thanks for the pioneering works [Body2hands](https://github.com/facebookresearch/body2hands) and [Frankmocap](https://github.com/facebookresearch/frankmocap).
## Citing

If you use our code, please cite our work

```
@InProceedings{Qi_2023_CVPR,
    author    = {Qi, Xingqun and Liu, Chen and Sun, Muyi and Li, Lincheng and Fan, Changjie and Yu, Xin},
    title     = {Diverse 3D Hand Gesture Prediction From Body Dynamics by Bilateral Hand Disentanglement},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {4616-4626}
}
```
